{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install catboost\n",
        "! pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "30nf0HbKAoqU",
        "outputId": "530b4b86-b437-41b4-c112-f03c604cfe8a"
      },
      "id": "30nf0HbKAoqU",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "23188b74a79b4f8dae9763c2eac81684"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3eafcfee-6a83-416c-b087-fa322648cd6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eafcfee-6a83-416c-b087-fa322648cd6d",
        "outputId": "283fad89-9615-46a9-b087-6c36a0935773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import numba as nb\n",
        "from numba import njit, prange,jit\n",
        "import cupy as cp\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Инициализация устройств\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "# Конфигурация\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGLeJWRlAul4",
        "outputId": "13de6762-e717-49c2-c050-e3286183fd5e"
      },
      "id": "WGLeJWRlAul4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a33322ee-8842-4b74-9383-8c7ee16ff29d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a33322ee-8842-4b74-9383-8c7ee16ff29d",
        "outputId": "0b53ddab-1577-426e-c78e-b4872a79305c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n"
          ]
        }
      ],
      "source": [
        "# Функция для анализа текста с CatBoost\n",
        "\n",
        "def analyze_text_with_catboost(texts, vectorizer, model):\n",
        "    X = vectorizer.transform(texts)\n",
        "    results = np.empty(len(texts), dtype=np.float32)\n",
        "    for i in prange(len(texts)):\n",
        "        results[i] = model.predict_proba(X[i])[0][1]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Загрузка данных\n",
        "#@njit\n",
        "def load_data(path):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "print(\"Загрузка данных...\")\n",
        "df = load_data('/content/drive/MyDrive/data/toxic_comments.csv')\n",
        "\n",
        "# Явное приведение к строке\n",
        "\n",
        "def convert_to_string(obj):\n",
        "\n",
        "    return str(obj).encode('utf-8').decode('utf-8')\n",
        "\n",
        "#df['text'] = convert_to_string(df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51d4931c-6702-428d-8ed3-194e548d2155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d4931c-6702-428d-8ed3-194e548d2155",
        "outputId": "d87dce0c-fdf3-4118-85ac-d56ab8d29b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предобработка текста...\n"
          ]
        }
      ],
      "source": [
        "# Предобработка текста\n",
        "\n",
        "def preprocess_text_gpu(texts):\n",
        "    processed = []\n",
        "    for i in prange(len(texts)):\n",
        "        text = str(texts[i]).lower()\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        processed.append(text)\n",
        "    return processed\n",
        "\n",
        "print(\"Предобработка текста...\")\n",
        "df['text_clean'] = preprocess_text_gpu(df['text'].values)\n",
        "y = df['toxic'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6016c054-9c8a-4b91-a24a-3c728d001267",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6016c054-9c8a-4b91-a24a-3c728d001267",
        "outputId": "42c31839-0ecb-47cf-cc90-d7a8a55e93bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text  toxic  \\\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1           1  D'aww! He matches this background colour I'm s...      0   \n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                          text_clean  \n",
              "0  explanation\\nwhy the edits made under my usern...  \n",
              "1  daww he matches this background colour im seem...  \n",
              "2  hey man im really not trying to edit war its j...  \n",
              "3  \\nmore\\ni cant make any real suggestions on im...  \n",
              "4  you sir are my hero any chance you remember wh...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-095cf1e7-bc95-45db-bd21-120931ec209f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>\\nmore\\ni cant make any real suggestions on im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-095cf1e7-bc95-45db-bd21-120931ec209f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-095cf1e7-bc95-45db-bd21-120931ec209f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-095cf1e7-bc95-45db-bd21-120931ec209f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a9cc79d6-481d-45b4-a77a-9e961e03eec7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9cc79d6-481d-45b4-a77a-9e961e03eec7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a9cc79d6-481d-45b4-a77a-9e961e03eec7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9c13c2-a5ce-49b4-8162-2258084ec793",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9c13c2-a5ce-49b4-8162-2258084ec793",
        "outputId": "ba16d82f-239c-4b42-e7ba-8d4d2e198f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF токенизация...\n"
          ]
        }
      ],
      "source": [
        "# 1. TF-IDF Токенизация\n",
        "print(\"TF-IDF токенизация...\")\n",
        "tfidf = TfidfVectorizer(max_features=5000,ngram_range=(1, 5),stop_words= 'english')\n",
        "X_tfidf = tfidf.fit_transform(df['text_clean'])\n",
        "X_tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a296cc-d908-41a7-9c11-7365ebc036e2",
      "metadata": {
        "id": "33a296cc-d908-41a7-9c11-7365ebc036e2"
      },
      "outputs": [],
      "source": [
        "# 2. Word2Vec Токенизация\n",
        "\n",
        "def tokenize_texts(texts):\n",
        "    tokens = []\n",
        "    for i in prange(len(texts)):\n",
        "        tokens.append(simple_preprocess(str(texts[i]), deacc=True))\n",
        "    return tokens\n",
        "\n",
        "print(\"Word2Vec токенизация...\")\n",
        "sentences = tokenize_texts(df['text_clean'].values)\n",
        "\n",
        "print(\"Обучение Word2Vec модели...\")\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "\n",
        "def text_to_vector_gpu(texts, model):\n",
        "    vectors = np.empty((len(texts), model.vector_size), dtype=np.float32)\n",
        "    for i in prange(len(texts)):\n",
        "        words = simple_preprocess(str(texts[i]), deacc=True)\n",
        "        word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
        "        vectors[i] = np.mean(word_vecs, axis=0) if len(word_vecs) > 0 else np.zeros(model.vector_size)\n",
        "    return vectors\n",
        "\n",
        "print(\"Создание Word2Vec векторов...\")\n",
        "X_w2v = text_to_vector_gpu(df['text_clean'].values, w2v_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f593358-58c2-47d2-9c82-6d7509f3e578",
      "metadata": {
        "id": "7f593358-58c2-47d2-9c82-6d7509f3e578"
      },
      "outputs": [],
      "source": [
        "# 3. BERT Токенизация и получение эмбеддингов\n",
        "print(\"Инициализация BERT...\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert') #('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained(('unitary/toxic-bert')).to(device)\n",
        "\n",
        "\n",
        "def bert_tokenize(texts):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = bert_tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
        "\n",
        "print(\"BERT токенизация...\")\n",
        "input_ids, attention_masks = bert_tokenize(df['text_clean'].tolist())\n",
        "\n",
        "\n",
        "def get_bert_embeddings(input_ids, attention_masks):\n",
        "    bert_model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "            batch_ids = input_ids[i:i+BATCH_SIZE].to(device)\n",
        "            batch_masks = attention_masks[i:i+BATCH_SIZE].to(device)\n",
        "\n",
        "            outputs = bert_model(batch_ids, attention_mask=batch_masks)\n",
        "            embeddings.append(outputs.last_hidden_state[:,0,:].cpu().numpy())\n",
        "\n",
        "    return np.concatenate(embeddings, axis=0)\n",
        "\n",
        "print(\"Получение BERT эмбеддингов...\")\n",
        "X_bert = get_bert_embeddings(input_ids, attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c0bfc5-eb32-497b-9d34-08e2f17392a5",
      "metadata": {
        "id": "66c0bfc5-eb32-497b-9d34-08e2f17392a5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc56320-524e-4923-bb69-1c7ab62bc0e7",
      "metadata": {
        "id": "2bc56320-524e-4923-bb69-1c7ab62bc0e7"
      },
      "outputs": [],
      "source": [
        "# Модели с GPU поддержкой\n",
        "models = {\n",
        "    'CatBoost': CatBoostClassifier(task_type='GPU', iterations=500, verbose=0),\n",
        "    'XGBoost': XGBClassifier(tree_method='gpu_hist', gpu_id=0),\n",
        "    'LightGBM': LGBMClassifier(device='gpu')\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "def evaluate_model(X, y, model, n_splits=3):\n",
        "    scores = []\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    fold_size = X.shape[0] // n_splits\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        test_idx = indices[i*fold_size:(i+1)*fold_size]\n",
        "        train_idx = np.concatenate([indices[:i*fold_size], indices[(i+1)*fold_size:]])\n",
        "\n",
        "        model.fit(X[train_idx], y[train_idx])\n",
        "        y_pred = model.predict(X[test_idx])\n",
        "        scores.append(f1_score(y[test_idx], y_pred))\n",
        "\n",
        "    return np.mean(scores), np.std(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe99710-73b3-4225-a24b-2950b20f3555",
      "metadata": {
        "id": "0fe99710-73b3-4225-a24b-2950b20f3555",
        "outputId": "4fe1684a-773b-49fd-c920-ec0c2fd47d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Оценка моделей:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 950.1027355 Total: 2047.875\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Оценка всех комбинаций\n",
        "results = []\n",
        "\n",
        "print(\"\\nОценка моделей:\")\n",
        "for name, model in models.items():\n",
        "    # TF-IDF\n",
        "    mean_f1, std_f1 = evaluate_model(X_tfidf, y, model)\n",
        "    results.append({'Модель': name, 'Токенизация': 'TF-IDF', 'F1': mean_f1, 'Std': std_f1})\n",
        "\n",
        "    # Word2Vec\n",
        "    mean_f1, std_f1 = evaluate_model(X_w2v, y, model)\n",
        "    results.append({'Модель': name, 'Токенизация': 'Word2Vec', 'F1': mean_f1, 'Std': std_f1})\n",
        "\n",
        "    # BERT\n",
        "    mean_f1, std_f1 = evaluate_model(X_bert, y, model)\n",
        "    results.append({'Модель': name, 'Токенизация': 'BERT', 'F1': mean_f1, 'Std': std_f1})\n",
        "\n",
        "# Результаты\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nРезультаты кросс-валидации:\")\n",
        "print(results_df)\n",
        "\n",
        "# Анализ с CatBoost\n",
        "print(\"\\nАнализ текста с CatBoost...\")\n",
        "best_model = CatBoostClassifier(task_type='GPU', iterations=500, verbose=0)\n",
        "best_model.fit(X_tfidf, y)\n",
        "text_analysis = analyze_text_with_catboost(df['text_clean'].values, tfidf, best_model)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(text_analysis, bins=50, alpha=0.7)\n",
        "plt.title('Распределение вероятностей токсичности')\n",
        "plt.xlabel('Вероятность токсичности')\n",
        "plt.ylabel('Количество комментариев')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "results_df.groupby(['Модель', 'Токенизация'])['F1'].mean().unstack().plot(kind='bar')\n",
        "plt.title('Сравнение методов токенизации')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d53e460-86bc-4eac-ad70-46321db67558",
      "metadata": {
        "id": "4d53e460-86bc-4eac-ad70-46321db67558"
      },
      "outputs": [],
      "source": [
        "# CNN модель\n",
        "def build_cnn_model(vocab_size=5000, max_len=100):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 64, input_length=max_len),\n",
        "        Conv1D(64, 5, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Кросс-валидация\n",
        "def evaluate_models(X, y, vectorizers, models):\n",
        "    results = []\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    for vec_name, vec in vectorizers.items():\n",
        "        for model_name, model in models.items():\n",
        "            pipeline = Pipeline([('vectorizer', vec), ('model', model)])\n",
        "            scores = cross_val_score(pipeline, X, y, cv=skf, scoring='f1', n_jobs=-1)\n",
        "            results.append({\n",
        "                'vectorizer': vec_name,\n",
        "                'model': model_name,\n",
        "                'f1_mean': np.mean(scores),\n",
        "                'f1_std': np.std(scores)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7207aacf-c1c0-4e79-a17a-18944b953074",
      "metadata": {
        "id": "7207aacf-c1c0-4e79-a17a-18944b953074"
      },
      "outputs": [],
      "source": [
        "# Оценка для каждого типа токенизации\n",
        "results_simple = evaluate_models(X['text_simple'], y, vectorizers, models)\n",
        "results_lemmatized = evaluate_models(X['text_lemmatized'], y, vectorizers, models)\n",
        "results_pos = evaluate_models(X['text_pos'], y, vectorizers, models)\n",
        "torch.cuda.empty_cache()\n",
        "# Объединение результатов\n",
        "results_all = pd.concat([\n",
        "    results_simple.assign(tokenization='simple'),\n",
        "    results_lemmatized.assign(tokenization='lemmatized'),\n",
        "    results_pos.assign(tokenization='pos_tags')\n",
        "])\n",
        "\n",
        "# CNN оценка\n",
        "def evaluate_cnn(X_texts, y, tokenization_type):\n",
        "    tokenizer = Tokenizer(num_words=5000)\n",
        "    tokenizer.fit_on_texts(X_texts)\n",
        "    X_seq = tokenizer.texts_to_sequences(X_texts)\n",
        "    X_pad = pad_sequences(X_seq, maxlen=100)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_idx, test_idx in skf.split(X_pad, y):\n",
        "        model = build_cnn_model()\n",
        "        model.fit(X_pad[train_idx], y[train_idx], epochs=3, batch_size=64, verbose=0)\n",
        "        y_pred = (model.predict(X_pad[test_idx]) > 0.5).astype(int)\n",
        "        f1_scores.append(f1_score(y[test_idx], y_pred))\n",
        "\n",
        "    return {\n",
        "        'vectorizer': 'embedding',\n",
        "        'model': 'CNN',\n",
        "        'f1_mean': np.mean(f1_scores),\n",
        "        'f1_std': np.std(f1_scores),\n",
        "        'tokenization': tokenization_type\n",
        "    }\n",
        "\n",
        "# Добавляем CNN результаты\n",
        "cnn_results = [\n",
        "    evaluate_cnn(X['text_simple'], y, 'simple'),\n",
        "    evaluate_cnn(X['text_lemmatized'], y, 'lemmatized'),\n",
        "    evaluate_cnn(X['text_pos'], y, 'pos_tags')\n",
        "]\n",
        "\n",
        "results_all = pd.concat([results_all, pd.DataFrame(cnn_results)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c2016c-ae6c-4e53-a674-3b667f0892db",
      "metadata": {
        "id": "c5c2016c-ae6c-4e53-a674-3b667f0892db"
      },
      "outputs": [],
      "source": [
        "# Анализ результатов\n",
        "print(\"Лучшие комбинации по типу токенизации:\")\n",
        "print(results_all.groupby('tokenization').apply(lambda x: x.nlargest(3, 'f1_mean')))\n",
        "\n",
        "print(\"\\nЛучшие комбинации по модели:\")\n",
        "print(results_all.groupby('model').apply(lambda x: x.nlargest(3, 'f1_mean')))\n",
        "\n",
        "print(\"\\nЛучшие комбинации по векторйзеру:\")\n",
        "print(results_all.groupby('vectorizer').apply(lambda x: x.nlargest(3, 'f1_mean')))\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(15, 8))\n",
        "for token_type in results_all['tokenization'].unique():\n",
        "    subset = results_all[results_all['tokenization'] == token_type]\n",
        "    plt.errorbar(subset['model'], subset['f1_mean'], yerr=subset['f1_std'],\n",
        "                fmt='o', label=token_type, capsize=5)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Сравнение моделей по типам токенизации')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c48f39-f18e-4ab4-8dfc-524ef01371d1",
      "metadata": {
        "id": "58c48f39-f18e-4ab4-8dfc-524ef01371d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd830625-0f6e-463d-826f-48110c3638ee",
      "metadata": {
        "id": "dd830625-0f6e-463d-826f-48110c3638ee"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}