{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mihail-Chr/projects/blob/main/ozon/ozon_cat_polars_CBLOF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "78e4d8bd-1a8c-4732-a4f9-4dc55175201c",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78e4d8bd-1a8c-4732-a4f9-4dc55175201c",
        "outputId": "b3ad2942-b5ff-43c6-9b99-70cb6e8d4df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: suod in /usr/local/lib/python3.12/dist-packages (0.1.4)\n",
            "Requirement already satisfied: combo in /usr/local/lib/python3.12/dist-packages (from suod) (0.1.3)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from suod) (1.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from suod) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.12/dist-packages (from suod) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from suod) (1.16.1)\n",
            "Requirement already satisfied: scikit_learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from suod) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from suod) (2.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from suod) (5.9.5)\n",
            "Requirement already satisfied: pyod>=1.0 in /usr/local/lib/python3.12/dist-packages (from suod) (2.0.5)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.12/dist-packages (from pyod>=1.0->suod) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51->pyod>=1.0->suod) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>=1.0->suod) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->suod) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->suod) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->suod) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->suod) (2025.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.25.2)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting yake\n",
            "  Downloading yake-0.6.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.12/dist-packages (from yake) (8.2.1)\n",
            "Collecting jellyfish (from yake)\n",
            "  Downloading jellyfish-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from yake) (3.5)\n",
            "Collecting segtok (from yake)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from yake) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from segtok->yake) (2024.11.6)\n",
            "Downloading yake-0.6.0-py3-none-any.whl (80 kB)\n",
            "Downloading jellyfish-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [yake]\n",
            "\u001b[1A\u001b[2KSuccessfully installed jellyfish-1.2.0 segtok-1.5.11 yake-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --use-pep517 suod\n",
        "!pip install -U pip\n",
        "!pip install polars catboost yake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7a0e03f8-876b-4f9a-8c21-6bbd39bf0453",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a0e03f8-876b-4f9a-8c21-6bbd39bf0453",
        "outputId": "0188729d-f8de-4d82-a8bf-9265a8075027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU недоступен, используем CPU\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
        "from sklearn.metrics import f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import gc\n",
        "import yake\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "len_word = 10\n",
        "\n",
        "RANDOM_STATE = 255\n",
        "\n",
        "try:\n",
        "    from catboost.utils import get_gpu_device_count\n",
        "    gpu_count = get_gpu_device_count()\n",
        "except ImportError:\n",
        "    gpu_count = 0\n",
        "\n",
        "if gpu_count > 0:\n",
        "    print(f\"GPU доступен, количество устройств: {gpu_count}\")\n",
        "    task_type = 'GPU'\n",
        "else:\n",
        "    print(\"GPU недоступен, используем CPU\")\n",
        "    task_type = 'CPU'\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "n_jobs = 3\n",
        "custom_stopwords = {\"для\", \"в\", \"с\",\"при\",\"вы\",\"не\",\"от\",\"что\",\"это\",\"на\",\"к\",\n",
        "                    'from','and','on','to','for','with','that','this','what','who'}\n",
        "\n",
        "pattern_clean = re.compile(r'[^а-яА-ЯёЁa-zA-Z0-9\\s\\(\\)\\{\\}\\[\\]]')\n",
        "\n",
        "stop_word = stop_words.union(custom_stopwords)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "849ec964-c9fa-42d9-a15e-442aee589ad4",
      "metadata": {
        "id": "849ec964-c9fa-42d9-a15e-442aee589ad4"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    cleaned = pattern_clean.sub('', text)\n",
        "    return cleaned.lower().strip()\n",
        "\n",
        "def extract_words(text, max_len=100, stop_words=None, top_k=20):\n",
        "\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return ''\n",
        "\n",
        "    shortened = text if len(text) <= max_len else text[:max_len]\n",
        "    kw_extractor = yake.KeywordExtractor(n=5,top=top_k, lan=\"ru\", stopwords=stop_words or set())\n",
        "    keywords = kw_extractor.extract_keywords(shortened)\n",
        "    if not keywords:\n",
        "        return ''\n",
        "    return keywords[0][0]\n",
        "\n",
        "def process_chunk(texts_chunk, stop_words=stop_word, top_k=len_word, n_jobs=3):\n",
        "    gc.collect()\n",
        "    results = Parallel(n_jobs=n_jobs)(delayed(extract_words)(text, max_len=100, stop_words=stop_words, top_k=top_k) for text in texts_chunk)\n",
        "\n",
        "    gc.collect()\n",
        "    return results\n",
        "\n",
        "def chunker(seq, size):\n",
        "    for pos in range(0, len(seq), size):\n",
        "        yield seq[pos:pos + size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0efcaf-fc8a-4c2d-8651-f51ec534748e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be0efcaf-fc8a-4c2d-8651-f51ec534748e",
        "outputId": "68b42cb0-6f3e-49e7-d2e2-1ee2721f3137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обработка столбца name_rus...\n"
          ]
        }
      ],
      "source": [
        "# Загрузка и предварительная обработка с Polars\n",
        "file_path = \"/content/drive/MyDrive/data/ml_ozon_сounterfeit_train.csv\"\n",
        "df = pl.read_csv(file_path)\n",
        "\n",
        "target = 'resolution'\n",
        "col_imp = ['id','resolution','PriceDiscounted','item_time_alive','seller_time_alive']\n",
        "col_count = ['videos_published_count','photos_published_count','comments_published_count']\n",
        "col_num = ['PriceDiscounted','item_time_alive','seller_time_alive','videos_published_count','photos_published_count','comments_published_count']\n",
        "col_text = ['name_rus','CommercialTypeName4','brand_name' ]\n",
        "col_total = col_imp + col_count+col_text\n",
        "\n",
        "df_first = df.select(col_total)\n",
        "\n",
        "# Заполнение пропусков (Polars позволяет делать это эффективно)\n",
        "for col in col_count:\n",
        "    df_first = df_first.with_columns([pl.col(col).fill_null(0).cast(pl.Int32).alias(col)])\n",
        "\n",
        "for col in col_text:\n",
        "    df_first = df_first.with_columns([pl.col(col).fill_null(\"\").cast(pl.Utf8).alias(col)])\n",
        "\n",
        "custom_stopwords = {\"для\", \"в\", \"с\",\"при\",\"вы\",\"не\",\"от\",\"что\",\"это\",\"на\",\"к\",\n",
        "                    'from','and','on','to','for','with','that','this','what','who'}\n",
        "\n",
        "stop_word = stop_words.union(custom_stopwords)\n",
        "\n",
        "chunk_size = 1000\n",
        "\n",
        "# Обработка текстовых колонок\n",
        "for col in col_text:\n",
        "    print(f\"Обработка столбца {col}...\")\n",
        "    texts = df_first[col].to_list()\n",
        "    cleaned_texts = [clean_text(t) for t in texts]\n",
        "    all_results = []\n",
        "    for chunk in chunker(cleaned_texts, chunk_size):\n",
        "        chunk_results = process_chunk(chunk)\n",
        "        all_results.extend(chunk_results)\n",
        "    #df_first = df_first.with_column(pl.Series(name=col, values=all_results))\n",
        "    df_first = df_first.with_columns([pl.Series(all_results).alias(col)])\n",
        "\n",
        "gc.collect()\n",
        "df_pd = df_first.to_pandas()\n",
        "df_pd.to_csv('df_first.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2373e1b7-437c-458b-87b6-43b7c202b196",
      "metadata": {
        "id": "2373e1b7-437c-458b-87b6-43b7c202b196"
      },
      "outputs": [],
      "source": [
        "# Конвертация Polars DataFrame в Pandas для CatBoost И CBLOF\n",
        "#df_pd = df_first.to_pandas()\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=300)\n",
        "scaler = StandardScaler()\n",
        "# TF-IDF преобразование текстового столбца\n",
        "X_full = df_pd[col_num].copy()\n",
        "\n",
        "for nc in  col_num :\n",
        "    X_full[nc] = scaler.fit_transform(X_full[[nc]]).ravel()\n",
        "\n",
        "for tc in  col_text:\n",
        "    text_features = tfidf.fit_transform(df_pd[tc]).toarray()\n",
        "    #print(text_features)\n",
        "    X_full = np.hstack([X_full, text_features])\n",
        "\n",
        "cblof = CBLOF(contamination=0.1, n_clusters=4, alpha=0.9, beta=5, use_weights=False)\n",
        "\n",
        "cblof.fit(X_full)\n",
        "anom_preds = cblof.predict(X_full)  # 0 - нормальный, 1 - аномалия\n",
        "\n",
        "# Добавляем аномалии как отдельный числовой признак\n",
        "X_full_with_anom = np.hstack([X_full, anom_preds.reshape(-1,1)])\n",
        "\n",
        "\n",
        "np.savetxt('X_full_with_anom.txt', X_full_with_anom, delimiter=',')\n",
        "#X_full_with_anom.to_csv('X_full_with_anom.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc9c3a6-65bd-4fb0-a303-a099adddc694",
      "metadata": {
        "id": "8dc9c3a6-65bd-4fb0-a303-a099adddc694"
      },
      "outputs": [],
      "source": [
        "X = X_full_with_anom\n",
        "y = df_pd[target]\n",
        "gc.collect()\n",
        "#text_feature_indices = [X.columns.get_loc(c) for c in col_text]\n",
        "\n",
        "# Кросс-валидация CatBoost с параметрами\n",
        "param_grid = {\n",
        "    'depth': [10,12],\n",
        "    'learning_rate': [0.1],\n",
        "    'l2_leaf_reg': [1],\n",
        "    'iterations': [300],\n",
        "    'task_type': [task_type],\n",
        "    'gpu_ram_part': [0.8],\n",
        "    'loss_function': ['Logloss'],\n",
        "    'eval_metric': ['F1'],\n",
        "    'custom_metric':['Recall'],\n",
        "    'random_seed': [1],\n",
        "    'early_stopping_rounds': [3],\n",
        "    'use_best_model': [True],\n",
        "    'verbose': [1],\n",
        "    'thread_count': [3],\n",
        "    'allow_writing_files':[False],\n",
        "    'used_ram_limit': ['8gb']\n",
        "}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "best_score = -np.inf\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "for params in ParameterGrid(param_grid):\n",
        "    f1_scores = []\n",
        "    current_best_model = None\n",
        "    current_best_score = -np.inf\n",
        "\n",
        "    for train_idx, valid_idx in skf.split(X, y):\n",
        "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        train_pool = Pool(X_train, y_train)\n",
        "        valid_pool = Pool(X_valid, y_valid)\n",
        "\n",
        "        model = CatBoostClassifier(**params,class_weights=[1, 10])\n",
        "\n",
        "        model.fit(train_pool, eval_set=valid_pool, verbose=False, early_stopping_rounds=30)\n",
        "\n",
        "\n",
        "        preds = model.predict(valid_pool)\n",
        "        f1 = f1_score(y_valid, preds, average='macro')\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        if f1 > current_best_score:\n",
        "            current_best_score = f1\n",
        "            current_best_model = model\n",
        "\n",
        "        del train_pool, valid_pool\n",
        "        gc.collect()\n",
        "\n",
        "    mean_f1 = np.mean(f1_scores)\n",
        "    print(f\"Параметры: {params} -> Средний F1: {mean_f1:.4f}\")\n",
        "\n",
        "    if mean_f1 > best_score:\n",
        "        best_score = mean_f1\n",
        "        best_params = params\n",
        "        best_model = current_best_model\n",
        "\n",
        "    gc.collect()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df84142-3494-4045-8538-05618fc4d3ea",
      "metadata": {
        "id": "6df84142-3494-4045-8538-05618fc4d3ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"\\nЛучшие параметры: {best_params}\")\n",
        "print(f\"Лучший средний F1: {best_score:.4f}\")\n",
        "print(f\"\\nЛучшая модель: {best_model}\")\n",
        "\n",
        "preds = best_model.predict(X)\n",
        "print(\"\\nClassification report на всей выборке:\")\n",
        "print(classification_report(y, preds))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(best_model, X, y, cmap=plt.cm.Blues)\n",
        "plt.title(\"Матрица ошибок\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d93197-a408-445d-8f8f-183c616764ba",
      "metadata": {
        "id": "42d93197-a408-445d-8f8f-183c616764ba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "raw",
      "id": "6b12676a-418d-440c-83c3-85c9c50c41b6",
      "metadata": {
        "id": "6b12676a-418d-440c-83c3-85c9c50c41b6"
      },
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\n",
        "\n",
        "probs = model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_valid, probs)\n",
        "\n",
        "# Найти порог с балансом между precision и recall\n",
        "optimal_idx = np.argmax(recall - (1 - precision))\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"Оптимальный порог: {optimal_threshold}\")\n",
        "\n",
        "preds = (probs >= optimal_threshold).astype(int)\n",
        "print(classification_report(y_valid, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18053a36-fcf2-45c1-8731-11c432df9552",
      "metadata": {
        "id": "18053a36-fcf2-45c1-8731-11c432df9552"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/data//ml_ozon_сounterfeit_test.csv')\n",
        "df_test.info()\n",
        "\n",
        "col_imp = ['id','PriceDiscounted','item_time_alive','seller_time_alive']\n",
        "col_count = ['videos_published_count','photos_published_count','comments_published_count']\n",
        "col_num = ['PriceDiscounted','item_time_alive','seller_time_alive','videos_published_count','photos_published_count','comments_published_count']\n",
        "col_text = ['name_rus','CommercialTypeName4','brand_name' ]\n",
        "col_total = col_imp + col_count+col_text\n",
        "\n",
        "df_test1 = df_test.select(col_total)\n",
        "\n",
        "# Заполнение пропусков (Polars позволяет делать это эффективно)\n",
        "for col in col_count:\n",
        "    df_test1 = df_test1.with_columns([pl.col(col).fill_null(0).cast(pl.Int32).alias(col)])\n",
        "\n",
        "for col in col_text:\n",
        "    df_test1 = df_test1.with_columns([pl.col(col).fill_null(\"\").cast(pl.Utf8).alias(col)])\n",
        "\n",
        "\n",
        "\n",
        "# Обработка текстовых колонок\n",
        "for col in col_text:\n",
        "    print(f\"Обработка столбца {col}...\")\n",
        "    texts = df_test1[col].to_list()\n",
        "    cleaned_texts = [clean_text(t) for t in texts]\n",
        "    all_results = []\n",
        "    for chunk in chunker(cleaned_texts, chunk_size):\n",
        "        chunk_results = process_chunk(chunk)\n",
        "        all_results.extend(chunk_results)\n",
        "    #df_first = df_first.with_column(pl.Series(name=col, values=all_results))\n",
        "    df_test1 = df_test1.with_columns([pl.Series(all_results).alias(col)])\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "X_test_f = df_test1.to_pandas()\n",
        "X_test = X_test_f[col_num].copy()\n",
        "for nc in  col_num :\n",
        "    X_test[nc] = scaler.fit_transform(X_test[nc])\n",
        "\n",
        "for tc in  col_text:\n",
        "    text_features = tfidf.fit_transform(X_test_f[tc]).toarray()\n",
        "    #print(text_features)\n",
        "    X_test = np.hstack([X_test, text_features])\n",
        "\n",
        "cblof.fit(X_test)\n",
        "anom_preds = cblof.predict(X_full)  # 0 - нормальный, 1 - аномалия\n",
        "\n",
        "# Добавляем аномалии как отдельный числовой признак\n",
        "X_test_with_anom = np.hstack([X_test, anom_preds.reshape(-1,1)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predictions_test = best_model.predict(X_test_with_anom)\n",
        "probabilities_test = best_model.predict_proba(X_test_with_anom)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': df_test['id'],\n",
        "    'prediction': predictions_test\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_co.csv', index=False)\n",
        "\n",
        "\n",
        "print(f\"Создан файл submission_co.csv с {len(submission)} предсказаниями\")\n",
        "print(f\"Распределение предсказаний:\")\n",
        "print(submission['prediction'].value_counts())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9391d4fa-2819-49b0-9f1e-9b0a97fb50e9",
      "metadata": {
        "id": "9391d4fa-2819-49b0-9f1e-9b0a97fb50e9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}