{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e4d8bd-1a8c-4732-a4f9-4dc55175201c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: suod in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: combo in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (0.1.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (3.10.5)\n",
      "Requirement already satisfied: numpy>=1.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (1.16.1)\n",
      "Requirement already satisfied: scikit_learn>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (2.2.3)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (5.9.0)\n",
      "Requirement already satisfied: pyod>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from suod) (2.0.5)\n",
      "Requirement already satisfied: numba>=0.51 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyod>=1.0->suod) (0.61.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51->pyod>=1.0->suod) (0.44.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit_learn>=1.0->suod) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->suod) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->suod) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 suod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2b27b-1e36-4200-bbb7-0afc3180e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0e03f8-876b-4f9a-8c21-6bbd39bf0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU доступен, количество устройств: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rs_mi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from pyod.models.cblof import CBLOF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import f1_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import gc\n",
    "import yake\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "len_word = 10\n",
    "\n",
    "RANDOM_STATE = 255\n",
    "\n",
    "try:\n",
    "    from catboost.utils import get_gpu_device_count\n",
    "    gpu_count = get_gpu_device_count()\n",
    "except ImportError:\n",
    "    gpu_count = 0\n",
    "\n",
    "if gpu_count > 0:\n",
    "    print(f\"GPU доступен, количество устройств: {gpu_count}\")\n",
    "    task_type = 'GPU'\n",
    "else:\n",
    "    print(\"GPU недоступен, используем CPU\")\n",
    "    task_type = 'CPU'\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "n_jobs = 3\n",
    "custom_stopwords = {\"для\", \"в\", \"с\",\"при\",\"вы\",\"не\",\"от\",\"что\",\"это\",\"на\",\"к\",\n",
    "                    'from','and','on','to','for','with','that','this','what','who'}\n",
    "\n",
    "stop_word = stop_words.union(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849ec964-c9fa-42d9-a15e-442aee589ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    cleaned = re.sub(r'[^а-яА-ЯёЁa-zA-Z0-9\\s\\(\\)\\{\\}\\[\\]]', '', text)\n",
    "    return cleaned.lower().strip()\n",
    "\n",
    "def extract_words(text, max_len=100, stop_words=None, top_k=20):\n",
    "    \n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return ''\n",
    "    \n",
    "    shortened = text if len(text) <= max_len else text[:max_len]\n",
    "    kw_extractor = yake.KeywordExtractor(n=5,top=top_k, lan=\"ru\", stopwords=stop_words or set())\n",
    "    keywords = kw_extractor.extract_keywords(shortened)\n",
    "    if not keywords:\n",
    "        return ''\n",
    "    return keywords[0][0]\n",
    "    \n",
    "def process_chunk(texts_chunk, stop_words=stop_word, top_k=len_word, n_jobs=3):\n",
    "    gc.collect()\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(extract_words)(text, max_len=100, stop_words=stop_words, top_k=top_k) for text in texts_chunk)\n",
    "    \n",
    "    gc.collect()\n",
    "    return results\n",
    "\n",
    "def chunker(seq, size):\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq[pos:pos + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0efcaf-fc8a-4c2d-8651-f51ec534748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка столбца name_rus...\n",
      "Обработка столбца CommercialTypeName4...\n",
      "Обработка столбца brand_name...\n"
     ]
    }
   ],
   "source": [
    "# Загрузка и предварительная обработка с Polars\n",
    "file_path = \"OZON/ml_ozon_сounterfeit_data/ml_ozon_сounterfeit_train.csv\"\n",
    "df = pl.read_csv(file_path)\n",
    "\n",
    "target = 'resolution'\n",
    "col_imp = ['id','resolution','PriceDiscounted','item_time_alive','seller_time_alive']\n",
    "col_count = ['videos_published_count','photos_published_count','comments_published_count']\n",
    "col_num = ['PriceDiscounted','item_time_alive','seller_time_alive','videos_published_count','photos_published_count','comments_published_count']\n",
    "col_text = ['name_rus','CommercialTypeName4','brand_name' ]\n",
    "col_total = col_imp + col_count+col_text\n",
    "\n",
    "df_first = df.select(col_total)\n",
    "\n",
    "# Заполнение пропусков (Polars позволяет делать это эффективно)\n",
    "for col in col_count:\n",
    "    df_first = df_first.with_columns([pl.col(col).fill_null(0).cast(pl.Int32).alias(col)])\n",
    "\n",
    "for col in col_text:\n",
    "    df_first = df_first.with_columns([pl.col(col).fill_null(\"\").cast(pl.Utf8).alias(col)])\n",
    "\n",
    "custom_stopwords = {\"для\", \"в\", \"с\",\"при\",\"вы\",\"не\",\"от\",\"что\",\"это\",\"на\",\"к\",\n",
    "                    'from','and','on','to','for','with','that','this','what','who'}\n",
    "\n",
    "stop_word = stop_words.union(custom_stopwords)\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "# Обработка текстовых колонок\n",
    "for col in col_text:\n",
    "    print(f\"Обработка столбца {col}...\")\n",
    "    texts = df_first[col].to_list()\n",
    "    cleaned_texts = [clean_text(t) for t in texts]\n",
    "    all_results = []\n",
    "    for chunk in chunker(cleaned_texts, chunk_size):\n",
    "        chunk_results = process_chunk(chunk)\n",
    "        all_results.extend(chunk_results)\n",
    "    #df_first = df_first.with_column(pl.Series(name=col, values=all_results))\n",
    "    df_first = df_first.with_columns([pl.Series(all_results).alias(col)])\n",
    "\n",
    "gc.collect()\n",
    "df_pd = df_first.to_pandas()\n",
    "df_pd.to_csv('df_first.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2373e1b7-437c-458b-87b6-43b7c202b196",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Добавляем аномалии как отдельный числовой признак\u001b[39;00m\n\u001b[32m     23\u001b[39m X_full_with_anom = np.hstack([X_full, anom_preds.reshape(-\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m)])\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m X_full_with_anom.to_csv(\u001b[33m'\u001b[39m\u001b[33mX_full_with_anom.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# Конвертация Polars DataFrame в Pandas для CatBoost И CBLOF\n",
    "#df_pd = df_first.to_pandas()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=300)       \n",
    "scaler = StandardScaler()\n",
    "# TF-IDF преобразование текстового столбца\n",
    "X_full = df_pd[col_num].copy()\n",
    "\n",
    "for nc in  col_num :    \n",
    "    X_full[nc] = scaler.fit_transform(X_full[[nc]]).ravel()\n",
    "    \n",
    "for tc in  col_text:\n",
    "    text_features = tfidf.fit_transform(df_pd[tc]).toarray()\n",
    "    #print(text_features)\n",
    "    X_full = np.hstack([X_full, text_features])\n",
    "\n",
    "cblof = CBLOF(contamination=0.1, n_clusters=4, alpha=0.9, beta=5, use_weights=False)\n",
    "\n",
    "cblof.fit(X_full)\n",
    "anom_preds = cblof.predict(X_full)  # 0 - нормальный, 1 - аномалия\n",
    "\n",
    "# Добавляем аномалии как отдельный числовой признак\n",
    "X_full_with_anom = np.hstack([X_full, anom_preds.reshape(-1,1)])\n",
    "\n",
    "\n",
    "np.savetxt('X_full_with_anom.txt', X_full_with_anom, delimiter=',')\n",
    "#X_full_with_anom.to_csv('X_full_with_anom.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ff0b319-bc7e-402f-a583-8a1d367a79b0",
   "metadata": {},
   "source": [
    "# ячейка для запуска , если catboost вылетает \n",
    "#df_pd = pd.read_csv('df_first.csv')\n",
    "target = 'resolution'\n",
    "col_imp = ['id','resolution','PriceDiscounted','item_time_alive','seller_time_alive']\n",
    "col_count = ['videos_published_count','photos_published_count','comments_published_count']\n",
    "col_num = ['PriceDiscounted','item_time_alive','seller_time_alive','videos_published_count','photos_published_count','comments_published_count']\n",
    "col_text = ['name_rus','CommercialTypeName4','brand_name' ]#,'description'\n",
    "col_total = col_imp + col_count+col_text\n",
    "\n",
    "#df_first[col_text] = df_first[col_text].fillna('').astype('string')\n",
    "#text_feature_indice = [df_first.columns.get_loc(c) for c in col_text]\n",
    "#print(text_feature_indice)\n",
    "#print(df_first.head())\n",
    "#df_pd.info()\n",
    "#df_pd = df_pd.drop(columns=['Unnamed: 0']).copy()\n",
    "df_pd.info()\n",
    "print(df_pd.head())\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9c3a6-65bd-4fb0-a303-a099adddc694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры: {'allow_writing_files': False, 'custom_metric': 'Recall', 'depth': 10, 'early_stopping_rounds': 3, 'eval_metric': 'F1', 'gpu_ram_part': 0.8, 'iterations': 300, 'l2_leaf_reg': 1, 'learning_rate': 0.1, 'loss_function': 'Logloss', 'random_seed': 1, 'task_type': 'GPU', 'thread_count': 3, 'use_best_model': True, 'used_ram_limit': '8gb', 'verbose': 1} -> Средний F1: 0.8238\n"
     ]
    }
   ],
   "source": [
    "X = X_full_with_anom\n",
    "y = df_pd[target]\n",
    "gc.collect()\n",
    "#text_feature_indices = [X.columns.get_loc(c) for c in col_text]\n",
    "\n",
    "# Кросс-валидация CatBoost с параметрами\n",
    "param_grid = {\n",
    "    'depth': [10,12],\n",
    "    'learning_rate': [0.1],\n",
    "    'l2_leaf_reg': [1],\n",
    "    'iterations': [300],\n",
    "    'task_type': [task_type],\n",
    "    'gpu_ram_part': [0.8],\n",
    "    'loss_function': ['Logloss'],\n",
    "    'eval_metric': ['F1'],\n",
    "    'custom_metric':['Recall'],\n",
    "    'random_seed': [1],\n",
    "    'early_stopping_rounds': [3],\n",
    "    'use_best_model': [True],\n",
    "    'verbose': [1],\n",
    "    'thread_count': [3],\n",
    "    'allow_writing_files':[False],\n",
    "    'used_ram_limit': ['8gb']\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    f1_scores = []\n",
    "    current_best_model = None\n",
    "    current_best_score = -np.inf\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "           \n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        valid_pool = Pool(X_valid, y_valid)        \n",
    "        \n",
    "        model = CatBoostClassifier(**params,class_weights=[1, 10])\n",
    "\n",
    "        model.fit(train_pool, eval_set=valid_pool, verbose=False, early_stopping_rounds=30)             \n",
    "            \n",
    "        \n",
    "        preds = model.predict(valid_pool)\n",
    "        f1 = f1_score(y_valid, preds, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        if f1 > current_best_score:\n",
    "            current_best_score = f1\n",
    "            current_best_model = model\n",
    "\n",
    "        del train_pool, valid_pool\n",
    "        gc.collect()\n",
    "\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    print(f\"Параметры: {params} -> Средний F1: {mean_f1:.4f}\")\n",
    "\n",
    "    if mean_f1 > best_score:\n",
    "        best_score = mean_f1\n",
    "        best_params = params\n",
    "        best_model = current_best_model\n",
    "    \n",
    "    gc.collect()    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df84142-3494-4045-8538-05618fc4d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(f\"\\nЛучшие параметры: {best_params}\")\n",
    "print(f\"Лучший средний F1: {best_score:.4f}\")\n",
    "print(f\"\\nЛучшая модель: {best_model}\")\n",
    "\n",
    "preds = best_model.predict(X)\n",
    "print(\"\\nClassification report на всей выборке:\")\n",
    "print(classification_report(y, preds))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(best_model, X, y, cmap=plt.cm.Blues)\n",
    "plt.title(\"Матрица ошибок\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d93197-a408-445d-8f8f-183c616764ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6b12676a-418d-440c-83c3-85c9c50c41b6",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\n",
    "\n",
    "probs = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, probs)\n",
    "\n",
    "# Найти порог с балансом между precision и recall\n",
    "optimal_idx = np.argmax(recall - (1 - precision))\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Оптимальный порог: {optimal_threshold}\")\n",
    "\n",
    "preds = (probs >= optimal_threshold).astype(int)\n",
    "print(classification_report(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18053a36-fcf2-45c1-8731-11c432df9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('OZON/ml_ozon_сounterfeit_data/ml_ozon_сounterfeit_test.csv')\n",
    "df_test.info()\n",
    "\n",
    "col_imp = ['id','PriceDiscounted','item_time_alive','seller_time_alive']\n",
    "col_count = ['videos_published_count','photos_published_count','comments_published_count']\n",
    "col_num = ['PriceDiscounted','item_time_alive','seller_time_alive','videos_published_count','photos_published_count','comments_published_count']\n",
    "col_text = ['name_rus','CommercialTypeName4','brand_name' ]\n",
    "col_total = col_imp + col_count+col_text\n",
    "\n",
    "df_test1 = df_test.select(col_total)\n",
    "\n",
    "# Заполнение пропусков (Polars позволяет делать это эффективно)\n",
    "for col in col_count:\n",
    "    df_test1 = df_test1.with_columns([pl.col(col).fill_null(0).cast(pl.Int32).alias(col)])\n",
    "\n",
    "for col in col_text:\n",
    "    df_test1 = df_test1.with_columns([pl.col(col).fill_null(\"\").cast(pl.Utf8).alias(col)])\n",
    "\n",
    "\n",
    "\n",
    "# Обработка текстовых колонок\n",
    "for col in col_text:\n",
    "    print(f\"Обработка столбца {col}...\")\n",
    "    texts = df_test1[col].to_list()\n",
    "    cleaned_texts = [clean_text(t) for t in texts]\n",
    "    all_results = []\n",
    "    for chunk in chunker(cleaned_texts, chunk_size):\n",
    "        chunk_results = process_chunk(chunk)\n",
    "        all_results.extend(chunk_results)\n",
    "    #df_first = df_first.with_column(pl.Series(name=col, values=all_results))\n",
    "    df_test1 = df_test1.with_columns([pl.Series(all_results).alias(col)])\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "X_test_f = df_test1.to_pandas()\n",
    "X_test = X_test_f[col_num].copy()\n",
    "for nc in  col_num :    \n",
    "    X_test[nc] = scaler.fit_transform(X_test[nc])\n",
    "    \n",
    "for tc in  col_text:\n",
    "    text_features = tfidf.fit_transform(X_test_f[tc]).toarray()\n",
    "    #print(text_features)\n",
    "    X_test = np.hstack([X_test, text_features])\n",
    "\n",
    "cblof.fit(X_test)\n",
    "anom_preds = cblof.predict(X_full)  # 0 - нормальный, 1 - аномалия\n",
    "\n",
    "# Добавляем аномалии как отдельный числовой признак\n",
    "X_test_with_anom = np.hstack([X_test, anom_preds.reshape(-1,1)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions_test = best_model.predict(X_test_with_anom)\n",
    "probabilities_test = best_model.predict_proba(X_test_with_anom)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'prediction': predictions_test\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_co.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"Создан файл submission_co.csv с {len(submission)} предсказаниями\")\n",
    "print(f\"Распределение предсказаний:\")\n",
    "print(submission['prediction'].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391d4fa-2819-49b0-9f1e-9b0a97fb50e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
