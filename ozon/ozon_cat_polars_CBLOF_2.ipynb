{
 "cells": [
  {
   "cell_type": "raw",
   "id": "814540f9-64be-4673-8d2f-0c13f68cf1b6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install --use-pep517 suod "
   ]
  },
  {
   "cell_type": "raw",
   "id": "17f74ce6-f4b2-47ad-a37f-595ee906af87",
   "metadata": {},
   "source": [
    "!conda install threadpoolctl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0e03f8-876b-4f9a-8c21-6bbd39bf0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU доступен, количество устройств: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rs_mi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from pyod.models.cblof import CBLOF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import f1_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import gc\n",
    "import yake\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "len_word = 10\n",
    "\n",
    "RANDOM_STATE = 255\n",
    "\n",
    "try:\n",
    "    from catboost.utils import get_gpu_device_count\n",
    "    gpu_count = get_gpu_device_count()\n",
    "except ImportError:\n",
    "    gpu_count = 0\n",
    "\n",
    "if gpu_count > 0:\n",
    "    print(f\"GPU доступен, количество устройств: {gpu_count}\")\n",
    "    task_type = 'GPU'\n",
    "else:\n",
    "    print(\"GPU недоступен, используем CPU\")\n",
    "    task_type = 'CPU'\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "n_jobs = 3\n",
    "custom_stopwords = {\"для\", \"в\", \"с\",\"при\",\"вы\",\"не\",\"от\",\"что\",\"это\",\"на\",\"к\",\n",
    "                    'from','and','on','to','for','with','that','this','what','who'}\n",
    "\n",
    "stop_word = stop_words.union(custom_stopwords)\n",
    "\n",
    "chunk_size = 1000\n",
    "pattern_clean = re.compile(r'[^а-яА-ЯёЁa-zA-Z0-9\\s\\(\\)\\{\\}\\[\\]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849ec964-c9fa-42d9-a15e-442aee589ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    cleaned = pattern_clean.sub('', text)\n",
    "    return cleaned.lower().strip()\n",
    "\n",
    "def extract_words(text, max_len=300, stop_words=None, top_k=20):\n",
    "    \n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return ''\n",
    "    \n",
    "    shortened = text if len(text) <= max_len else text[:max_len]\n",
    "    kw_extractor = yake.KeywordExtractor(n=3,top=top_k, lan=\"ru\", stopwords=stop_words or set())\n",
    "    keywords = kw_extractor.extract_keywords(shortened)\n",
    "    if not keywords:\n",
    "        return ''\n",
    "    return keywords[0][0]\n",
    "    \n",
    "def process_chunk(texts_chunk, stop_words=stop_word, top_k=len_word, n_jobs=3):\n",
    "    gc.collect()\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(extract_words)(text, max_len=100, stop_words=stop_words, top_k=top_k) for text in texts_chunk)\n",
    "    \n",
    "    gc.collect()\n",
    "    return results\n",
    "\n",
    "def chunker(seq, size):\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq[pos:pos + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb2813d-258d-4c34-a641-5b6bcae0cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и предварительная обработка с Polars\n",
    "file_path = \"OZON/ml_ozon_сounterfeit_data/ml_ozon_сounterfeit_train.csv\"\n",
    "df = pl.read_csv(file_path)\n",
    "\n",
    "target = 'resolution'\n",
    "col_drop = ['id','ItemID','SellerID',]\n",
    "col_num = df.select(cs.numeric()).columns\n",
    "col_text = ['name_rus','CommercialTypeName4','brand_name' ]\n",
    "\n",
    "col_count = list(set(col_num)  - set(col_drop))\n",
    "col_total= []\n",
    "col_total.extend(col_count)\n",
    "col_total.extend(col_text)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=200)       \n",
    "scaler = StandardScaler()\n",
    "df_first = df.select(col_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ef8c0b-f157-4ddc-9603-86168bcb3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_text(df,col_text):\n",
    "   \n",
    "    for col in col_text:\n",
    "        df = df.with_columns([pl.col(col).fill_null(\"\").cast(pl.Utf8).alias(col)])\n",
    "        print(f\"Обработка столбца {col}...\")\n",
    "        texts = df[col].to_list()\n",
    "        cleaned_texts = [clean_text(t) for t in texts]\n",
    "        if col=='name_rus':\n",
    "            all_results = []\n",
    "            for chunk in chunker(cleaned_texts, chunk_size):\n",
    "                chunk_results = process_chunk(chunk)\n",
    "                all_results.extend(chunk_results)\n",
    "        else : all_results = cleaned_texts\n",
    "    \n",
    "        df = df.with_columns([pl.Series(all_results).alias(col)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7015bed7-2238-4a00-902c-7cc960654ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_count(df,col_count):\n",
    "    for col in col_count:\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).fill_null(0).cast(pl.Int32).alias(col))\n",
    "        df = df.with_columns([\n",
    "            (pl.col('OrderAcceptedCountTotal30') - pl.col('OrderAcceptedCountTotal7')).alias('OrderAcceptedCountT_30_7'),\n",
    "            (pl.col('OrderAcceptedCountTotal90') - pl.col('OrderAcceptedCountTotal30')).alias('OrderAcceptedCountT_90_30'),\n",
    "            (pl.col('item_count_fake_returns30') - pl.col('item_count_fake_returns7')).alias('item_fake_returns_30_7'),\n",
    "            (pl.col('item_count_fake_returns90') - pl.col('item_count_fake_returns30')).alias('item_fake_returns_90_30'),\n",
    "            (pl.col('item_count_sales30') - pl.col('item_count_sales7')).alias('item_count_sales_30_7'),\n",
    "            (pl.col('item_count_sales90') - pl.col('item_count_sales30')).alias('item_count_sales_90_30'),\n",
    "            (pl.col('item_count_fake_returns30') - pl.col('item_count_fake_returns7')).alias('item_count_returns_30_7'),\n",
    "            (pl.col('item_count_fake_returns90') - pl.col('item_count_fake_returns30')).alias('item_count_returns_90_30'),\n",
    "            (pl.col('ExemplarReturnedCountTotal30') - pl.col('ExemplarReturnedCountTotal7')).alias('ExemplarReturnedCount30_7'),\n",
    "            (pl.col('ExemplarReturnedCountTotal90') - pl.col('ExemplarReturnedCountTotal30')).alias('ExemplarReturnedCount90_30'),\n",
    "            (pl.col('ExemplarReturnedValueTotal30') - pl.col('ExemplarReturnedValueTotal7')).alias('ExemplarReturnedValue30_7'),\n",
    "            (pl.col('ExemplarReturnedValueTotal90') - pl.col('ExemplarReturnedValueTotal30')).alias('ExemplarReturnedValue90_30'),\n",
    "            (pl.col('ExemplarAcceptedCountTotal30') - pl.col('ExemplarAcceptedCountTotal7')).alias('ExemplarAcceptedCount30_7'),\n",
    "            (pl.col('ExemplarAcceptedCountTotal90') - pl.col('ExemplarAcceptedCountTotal30')).alias('ExemplarAcceptedCount90_30'),\n",
    "            (pl.col('GmvTotal30') - pl.col('GmvTotal7')).alias('Gmv30_7'),\n",
    "            (pl.col('GmvTotal90') - pl.col('GmvTotal30')).alias('Gmv90_30'),\n",
    "        ])\n",
    "\n",
    "    # Удаление ненужных колонок\n",
    "    drop_col2 = ['OrderAcceptedCountTotal90','OrderAcceptedCountTotal30','OrderAcceptedCountTotal7',\n",
    "                 'item_count_fake_returns7','item_count_fake_returns30','item_count_fake_returns90',\n",
    "                 'item_count_sales7','item_count_sales90','item_count_sales30',\n",
    "                 'item_count_returns30','item_count_returns90','item_count_returns7',\n",
    "                 'ExemplarAcceptedCountTotal30','ExemplarAcceptedCountTotal90','ExemplarAcceptedCountTotal7',\n",
    "                 'ExemplarReturnedCountTotal30','ExemplarReturnedCountTotal90','ExemplarReturnedCountTotal7',\n",
    "                 'ExemplarReturnedValueTotal7','ExemplarReturnedValueTotal90','ExemplarReturnedValueTotal30',\n",
    "                 'GmvTotal7','GmvTotal90','GmvTotal30']\n",
    "\n",
    "    df = df.drop(drop_col2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d081d81e-461a-42fa-9b4e-dccb79ef7310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка столбца name_rus...\n",
      "Обработка столбца CommercialTypeName4...\n",
      "Обработка столбца brand_name...\n"
     ]
    }
   ],
   "source": [
    "# Обработка текстовых колонок\n",
    "df_first = prep_text(df_first,col_text)\n",
    "\n",
    "# Обработка текстовых колонок\n",
    "#display(sorted(col_count))\n",
    "# Заполнение цифровых значений \n",
    "df_first = prep_count(df_first,col_count)\n",
    "gc.collect()\n",
    "df_pd = df_first.to_pandas()\n",
    "#df_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2373e1b7-437c-458b-87b6-43b7c202b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CBLOF # Добавляем аномалии как отдельный числовой признак\n",
    "\n",
    "def add_CBLOF(df,col_count,col_text):\n",
    "    X_full = df[col_count]\n",
    "    for tc in  col_text:\n",
    "        text_features = tfidf.fit_transform(df[tc]).toarray()    \n",
    "        X_full = np.hstack([X_full, text_features])\n",
    "\n",
    "    cblof = CBLOF(contamination=0.1, n_clusters=4, alpha=0.9, beta=5)#, use_weights=False)\n",
    "    cblof.fit(X_full)\n",
    "    anom_preds = cblof.predict(X_full)  # 0 - нормальный, 1 - аномалия\n",
    "    \n",
    "    return anom_preds.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ab06e0-d299-4c32-a56b-9c14a51921e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num2 = df_pd.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#display(col_num2)\n",
    "df_pd['cblof'] = add_CBLOF(df_pd,col_num2,col_text)\n",
    "\n",
    "for nc in  col_num2 :    \n",
    "    df_pd[nc] = scaler.fit_transform(df_pd[[nc]]).ravel()\n",
    "    \n",
    "\n",
    "df_pd.to_csv('df_first.csv', index=False)\n",
    "#df_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad7b25e-e3a9-481d-a062-7eb5a29eff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "X = df_pd.drop(target,axis=1 ).copy()\n",
    "y = df[target].to_pandas()\n",
    "gc.collect() \n",
    "text_feature_indices = [X.columns.get_loc(c) for c in col_text]\n",
    "print(text_feature_indices)\n",
    "#X.info() \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5013175a-4c48-483e-9f49-6e7ffe77df96",
   "metadata": {},
   "source": [
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "from phik import phik_matrix\n",
    "df_phik = X.copy()\n",
    "df_phik['target'] = y\n",
    "interval_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#df_phik = df_all.drop([], axis=1).copy()\n",
    "#df_phik = df_phik.drop(nul_col, axis=1).copy()\n",
    "# 'PHIK матрица'\n",
    "display ('PHIK матрица ')\n",
    "phik_overview = phik_matrix(df_phik, interval_cols=interval_cols) # .drop('id', axis=1) ['customerID', 'BeginDate', 'EndDate'\n",
    "plot_correlation_matrix(\n",
    "    phik_overview.values,\n",
    "    x_labels=phik_overview.columns,\n",
    "    y_labels=phik_overview.index,\n",
    "    vmin=0, vmax=1, color_map='Greens',\n",
    "    title=r'correlation $\\phi_K$',\n",
    "    fontsize_factor=0.8,\n",
    "    figsize=(12,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef6889-26b1-4c41-8537-d29a1df7dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры: {'allow_writing_files': False, 'custom_metric': 'Recall', 'depth': 12, 'early_stopping_rounds': 5, 'eval_metric': 'F1', 'gpu_ram_part': 0.8, 'iterations': 300, 'l2_leaf_reg': 1, 'learning_rate': 0.1, 'loss_function': 'Logloss', 'random_seed': 1, 'task_type': 'GPU', 'thread_count': 3, 'use_best_model': True, 'used_ram_limit': '8gb', 'verbose': 1} -> Средний F1: 0.8242\n"
     ]
    }
   ],
   "source": [
    "# Кросс-валидация CatBoost с параметрами старый вариант \n",
    "gc.collect() \n",
    "param_grid = {\n",
    "    'depth': [12,14],\n",
    "    'learning_rate': [0.1],\n",
    "    'l2_leaf_reg': [1],\n",
    "    'iterations': [300],\n",
    "    'task_type': [task_type],\n",
    "    'gpu_ram_part': [0.8],\n",
    "    'loss_function': ['Logloss'],\n",
    "    #'custom_loss': ['AUC'],\n",
    "    'eval_metric': ['F1'],\n",
    "    'custom_metric':['Recall'],\n",
    "    'random_seed': [1],\n",
    "    'early_stopping_rounds': [5],\n",
    "    'use_best_model': [True],\n",
    "    'verbose': [1],\n",
    "    'thread_count': [3],\n",
    "    'allow_writing_files':[False],\n",
    "    'used_ram_limit': ['8gb']\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    f1_scores = []\n",
    "    current_best_model = None\n",
    "    current_best_score = -np.inf\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "           \n",
    "        train_pool = Pool(X_train, y_train, text_features=text_feature_indices)\n",
    "        valid_pool = Pool(X_valid, y_valid, text_features=text_feature_indices)        \n",
    "        \n",
    "        model = CatBoostClassifier(**params,class_weights=[1, 14], text_features=text_feature_indices) #,class_weights=[1, 14]\n",
    "\n",
    "        model.fit(train_pool, eval_set=valid_pool, verbose=False, early_stopping_rounds=10)             \n",
    "            \n",
    "        \n",
    "        preds = model.predict(valid_pool)\n",
    "        f1 = f1_score(y_valid, preds, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        if f1 > current_best_score:\n",
    "            current_best_score = f1\n",
    "            current_best_model = model\n",
    "\n",
    "        del train_pool, valid_pool\n",
    "        gc.collect()\n",
    "\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    print(f\"Параметры: {params} -> Средний F1: {mean_f1:.4f}\")\n",
    "\n",
    "    if mean_f1 > best_score:\n",
    "        best_score = mean_f1\n",
    "        best_params = params\n",
    "        best_model = current_best_model\n",
    "    \n",
    "    gc.collect()    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df84142-3494-4045-8538-05618fc4d3ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mЛучшие параметры: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЛучший средний F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mЛучшая модель: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"\\nЛучшие параметры: {best_params}\")\n",
    "print(f\"Лучший средний F1: {best_score:.4f}\")\n",
    "print(f\"\\nЛучшая модель: {best_model}\")\n",
    "\n",
    "preds = best_model.predict(X)\n",
    "print(\"\\nClassification report на всей выборке:\")\n",
    "print(classification_report(y, preds))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(best_model, X, y, cmap=plt.cm.Blues)\n",
    "plt.title(\"Матрица ошибок\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea6e96-2829-472e-8744-cfae9749d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\n",
    "\n",
    "probs = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, probs)\n",
    "\n",
    "# Найти порог с балансом между precision и recall\n",
    "optimal_idx = np.argmax(recall - (1 - precision))\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Оптимальный порог: {optimal_threshold}\")\n",
    "\n",
    "preds = (probs >= optimal_threshold).astype(int)\n",
    "print(classification_report(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71629ed-12ca-4f0f-97e1-6d35b6d851a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pl.read_csv('OZON/ml_ozon_сounterfeit_data/ml_ozon_сounterfeit_test.csv')\n",
    "#df_test.info()\n",
    "\n",
    "\n",
    "# Обработка текстовых колонок\n",
    "df_test = prep_text(df_test,col_text)\n",
    "\n",
    "# Заполнение цифровых значений \n",
    "df_test = prep_count(df_test,col_count)\n",
    "\n",
    "gc.collect()\n",
    "df_test_pd = df_test.to_pandas()\n",
    "\n",
    "col_num2 = df_test.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "df_pd['cblof'] = add_CBLOF(df_test_pd,col_num2,col_text)\n",
    "\n",
    "for nc in  col_num2 :    \n",
    "    df_test_pd[nc] = scaler.fit_transform(df_test_pd[[nc]]).ravel()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5449bdf-f160-4766-be4f-8c6682979731",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = best_model.predict(df_test_pd)\n",
    "probabilities_test = best_model.predict_proba(df_test_pd)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'prediction': predictions_test\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_co.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"Создан файл submission_co.csv с {len(submission)} предсказаниями\")\n",
    "print(f\"Распределение предсказаний:\")\n",
    "print(submission['prediction'].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391d4fa-2819-49b0-9f1e-9b0a97fb50e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
